using System.Collections.ObjectModel;
using ChatCaster.Core.Events;
using ChatCaster.Core.Models;
using ChatCaster.Windows.Services;
using ChatCaster.Windows.ViewModels.Settings.Audio;
using Serilog;

namespace ChatCaster.Windows.ViewModels.Settings.Speech
{
    /// <summary>
    /// –ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –º–æ–¥–µ–ª—è–º–∏ Whisper
    /// </summary>
    public class WhisperModelManager
    {
        #region Events
        public event EventHandler<ModelStatusChangedEventArgs>? ModelStatusChanged;
        public event EventHandler<ModelDownloadButtonVisibilityChangedEventArgs>? DownloadButtonVisibilityChanged;
        #endregion

        #region Private Fields
        private readonly SpeechRecognitionService? _speechRecognitionService;
        private bool _isDownloadingModel = false;
        #endregion

        #region Public Properties
        public ObservableCollection<WhisperModelItem> AvailableModels { get; } = new();
        public ObservableCollection<LanguageItem> AvailableLanguages { get; } = new();
        public WhisperModelItem? SelectedModel { get; set; }
        public LanguageItem? SelectedLanguage { get; set; }
        public bool IsDownloadingModel => _isDownloadingModel;
        #endregion

        #region Constructor
        public WhisperModelManager(SpeechRecognitionService? speechRecognitionService)
        {
            Log.Information("[WMM] –ö–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä –≤—ã–∑–≤–∞–Ω");
            _speechRecognitionService = speechRecognitionService;
            InitializeStaticData();
            Log.Debug("WhisperModelManager –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω");
        }
        #endregion

        #region Public Methods

        /// <summary>
        /// –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—Ç–∞—Ç—É—Å –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
        /// </summary>
        public async Task CheckModelStatusAsync()
        {
            try
            {
                if (_speechRecognitionService == null || SelectedModel == null)
                {
                    Log.Warning("SpeechRecognitionService –∏–ª–∏ SelectedModel –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —Å—Ç–∞—Ç—É—Å–∞ –º–æ–¥–µ–ª–∏");
                    return;
                }

                // ‚úÖ –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê: –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–æ—Ü–µ—Å—Å –ø—Ä–æ–≤–µ—Ä–∫–∏
                Log.Information("=== –ü–†–û–í–ï–†–ö–ê –°–¢–ê–¢–£–°–ê –ú–û–î–ï–õ–ò ===");
                Log.Information("–í—ã–±—Ä–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –≤ UI: {UIModel} ({DisplayName})", SelectedModel.Model, SelectedModel.DisplayName);
                Log.Information("–ú–æ–¥–µ–ª—å –≤ SpeechRecognition: {ServiceModel}", _speechRecognitionService.CurrentModel);
                Log.Information("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –ª–∏ —Å–µ—Ä–≤–∏—Å: {IsInitialized}", _speechRecognitionService.IsInitialized);

                bool isAvailable = await _speechRecognitionService.IsModelAvailableAsync(SelectedModel.Model);
                Log.Information("–ú–æ–¥–µ–ª—å –¥–æ—Å—Ç—É–ø–Ω–∞ –Ω–∞ –¥–∏—Å–∫–µ: {IsAvailable}", isAvailable);

                if (isAvailable)
                {
                    // ‚úÖ –ö–õ–Æ–ß–ï–í–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω—É–∂–Ω–∞ –ª–∏ –ø–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
                    if (!_speechRecognitionService.IsInitialized || 
                        _speechRecognitionService.CurrentModel != SelectedModel.Model)
                    {
                        Log.Warning("–ù–£–ñ–ù–ê –ü–ï–†–ï–ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø! –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å {Model}", SelectedModel.Model);
                        
                        var config = new WhisperConfig { Model = SelectedModel.Model };
                        bool initResult = await _speechRecognitionService.InitializeAsync(config);
                        
                        Log.Information("–†–µ–∑—É–ª—å—Ç–∞—Ç –ø–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {InitResult}", initResult);
                        
                        if (initResult)
                        {
                            Log.Information("‚úÖ –ú–æ–¥–µ–ª—å {Model} —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –≤ —Å–µ—Ä–≤–∏—Å", SelectedModel.Model);
                        }
                        else
                        {
                            Log.Error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å {Model} –≤ —Å–µ—Ä–≤–∏—Å", SelectedModel.Model);
                            RaiseModelStatusChanged("–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏", "#f44336");
                            return;
                        }
                    }
                    else
                    {
                        Log.Information("‚úÖ –ù—É–∂–Ω–∞—è –º–æ–¥–µ–ª—å —É–∂–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞");
                    }

                    RaiseModelStatusChanged("–ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞", "#4caf50");
                    RaiseDownloadButtonVisibilityChanged(false);
                    Log.Debug("–ú–æ–¥–µ–ª—å {ModelName} –¥–æ—Å—Ç—É–ø–Ω–∞", SelectedModel.DisplayName);
                }
                else
                {
                    long sizeBytes = await _speechRecognitionService.GetModelSizeAsync(SelectedModel.Model);
                    string sizeText = FormatFileSize(sizeBytes);
                    RaiseModelStatusChanged($"–ú–æ–¥–µ–ª—å –Ω–µ —Å–∫–∞—á–∞–Ω–∞ ({sizeText})", "#ff9800");
                    RaiseDownloadButtonVisibilityChanged(true);
                    Log.Debug("–ú–æ–¥–µ–ª—å {ModelName} –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞, —Ä–∞–∑–º–µ—Ä: {Size}", SelectedModel.DisplayName, sizeText);
                }
                
                Log.Information("=== –ü–†–û–í–ï–†–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê ===");
            }
            catch (Exception ex)
            {
                RaiseModelStatusChanged($"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –º–æ–¥–µ–ª–∏: {ex.Message}", "#f44336");
                Log.Error(ex, "–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —Å—Ç–∞—Ç—É—Å–∞ –º–æ–¥–µ–ª–∏ {ModelName}", SelectedModel?.DisplayName ?? "Unknown");
            }
        }
        /// <summary>
        /// –ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—ã–±—Ä–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å
        /// </summary>
        public async Task DownloadModelAsync()
        {
            if (_isDownloadingModel || _speechRecognitionService == null || SelectedModel == null) return;

            try
            {
                _isDownloadingModel = true;
                RaiseModelStatusChanged("–ù–∞—á–∏–Ω–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É...", "#ff9800");
                Log.Debug("–ù–∞—á–∏–Ω–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É –º–æ–¥–µ–ª–∏: {ModelName}", SelectedModel.DisplayName);

                // –ü–æ–¥–ø–∏—Å—ã–≤–∞–µ–º—Å—è –Ω–∞ —Å–æ–±—ã—Ç–∏—è –∑–∞–≥—Ä—É–∑–∫–∏
                _speechRecognitionService.DownloadProgress += OnModelDownloadProgress;
                _speechRecognitionService.DownloadCompleted += OnModelDownloadCompleted;

                // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å (—ç—Ç–æ –∑–∞–ø—É—Å—Ç–∏—Ç –∑–∞–≥—Ä—É–∑–∫—É –µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
                var config = new WhisperConfig { Model = SelectedModel.Model };
                await _speechRecognitionService.InitializeAsync(config);
            }
            catch (Exception ex)
            {
                RaiseModelStatusChanged($"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {ex.Message}", "#f44336");
                Log.Error(ex, "–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–∏ {ModelName}", SelectedModel?.DisplayName ?? "Unknown");
                _isDownloadingModel = false;
            }
        }

        /// <summary>
        /// –ù–∞—Ö–æ–¥–∏—Ç –º–æ–¥–µ–ª—å –ø–æ enum –∑–Ω–∞—á–µ–Ω–∏—é
        /// </summary>
        public WhisperModelItem? FindModelByEnum(WhisperModel model)
        {
            return AvailableModels.FirstOrDefault(m => m.Model == model);
        }

        /// <summary>
        /// –ù–∞—Ö–æ–¥–∏—Ç —è–∑—ã–∫ –ø–æ –∫–æ–¥—É
        /// </summary>
        public LanguageItem? FindLanguageByCode(string languageCode)
        {
            if (string.IsNullOrEmpty(languageCode)) return null;
            return AvailableLanguages.FirstOrDefault(l => l.Code == languageCode);
        }

        /// <summary>
        /// –ü–æ–ª—É—á–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –¥–ª—è Whisper
        /// </summary>
        public WhisperConfig GetWhisperConfig()
        {
            return new WhisperConfig
            {
                Model = SelectedModel?.Model ?? WhisperModel.Base,
                Language = SelectedLanguage?.Code ?? "ru"
            };
        }

        /// <summary>
        /// –û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤
        /// </summary>
        public void Cleanup()
        {
            try
            {
                // –û—Ç–ø–∏—Å—ã–≤–∞–µ–º—Å—è –æ—Ç —Å–æ–±—ã—Ç–∏–π –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ –µ—Å–ª–∏ –ø–æ–¥–ø–∏—Å–∞–Ω—ã
                if (_speechRecognitionService != null)
                {
                    _speechRecognitionService.DownloadProgress -= OnModelDownloadProgress;
                    _speechRecognitionService.DownloadCompleted -= OnModelDownloadCompleted;
                }
                Log.Debug("WhisperModelManager cleanup –∑–∞–≤–µ—Ä—à–µ–Ω");
            }
            catch (Exception ex)
            {
                Log.Error(ex, "–û—à–∏–±–∫–∞ –ø—Ä–∏ cleanup WhisperModelManager");
            }
        }

        #endregion

        #region Private Methods

        private void InitializeStaticData()
        {
            Log.Information("[WMM] InitializeStaticData –≤—ã–∑–≤–∞–Ω");

            // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ Whisper
            AvailableModels.Clear();
            var models = WhisperModelFactory.CreateAvailableModels();
            foreach (var model in models)
            {
                AvailableModels.Add(model);
            }

            // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ —è–∑—ã–∫–∏
            AvailableLanguages.Clear();
            AvailableLanguages.Add(new LanguageItem("ru", "üá∑üá∫ –†—É—Å—Å–∫–∏–π"));
            AvailableLanguages.Add(new LanguageItem("en", "üá∫üá∏ English"));

            // –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            SelectedModel = WhisperModelFactory.GetDefaultModel();
            SelectedLanguage = AvailableLanguages.FirstOrDefault(l => l.Code == "ru");
            Log.Information("[WMM] AvailableModels –ø–æ—Å–ª–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: " + string.Join(", ", AvailableModels.Select(m => m.Model)));

        }

        private void OnModelDownloadProgress(object? sender, ModelDownloadProgressEvent e)
        {
            RaiseModelStatusChanged($"–ó–∞–≥—Ä—É–∑–∫–∞ {e.ProgressPercentage}%...", "#ff9800");
        }

        private void OnModelDownloadCompleted(object? sender, ModelDownloadCompletedEvent e)
        {
            // –û—Ç–ø–∏—Å—ã–≤–∞–µ–º—Å—è –æ—Ç —Å–æ–±—ã—Ç–∏–π
            if (_speechRecognitionService != null)
            {
                _speechRecognitionService.DownloadProgress -= OnModelDownloadProgress;
                _speechRecognitionService.DownloadCompleted -= OnModelDownloadCompleted;
            }

            if (e.Success)
            {
                RaiseModelStatusChanged("–ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞", "#4caf50");
                RaiseDownloadButtonVisibilityChanged(false);
                Log.Information("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∞");
            }
            else
            {
                RaiseModelStatusChanged($"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e.ErrorMessage}", "#f44336");
                Log.Error("–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {ErrorMessage}", e.ErrorMessage);
            }

            _isDownloadingModel = false;
        }

        private static string FormatFileSize(long bytes)
        {
            if (bytes >= 1_073_741_824) // GB
                return $"{bytes / 1_073_741_824.0:F1} GB";
            if (bytes >= 1_048_576) // MB
                return $"{bytes / 1_048_576.0:F0} MB";
            if (bytes >= 1024) // KB
                return $"{bytes / 1024.0:F0} KB";
            return $"{bytes} bytes";
        }

        private void RaiseModelStatusChanged(string status, string colorHex)
        {
            ModelStatusChanged?.Invoke(this, new ModelStatusChangedEventArgs(status, colorHex));
        }

        private void RaiseDownloadButtonVisibilityChanged(bool isVisible)
        {
            DownloadButtonVisibilityChanged?.Invoke(this, new ModelDownloadButtonVisibilityChangedEventArgs(isVisible));
        }

        #endregion
    }

    #region Event Args
    /// <summary>
    /// –ê—Ä–≥—É–º–µ–Ω—Ç—ã —Å–æ–±—ã—Ç–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞ –º–æ–¥–µ–ª–∏
    /// </summary>
    public class ModelStatusChangedEventArgs : EventArgs
    {
        public string Status { get; }
        public string ColorHex { get; }

        public ModelStatusChangedEventArgs(string status, string colorHex)
        {
            Status = status ?? throw new ArgumentNullException(nameof(status));
            ColorHex = colorHex ?? throw new ArgumentNullException(nameof(colorHex));
        }
    }

    /// <summary>
    /// –ê—Ä–≥—É–º–µ–Ω—Ç—ã —Å–æ–±—ã—Ç–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤–∏–¥–∏–º–æ—Å—Ç–∏ –∫–Ω–æ–ø–∫–∏ –∑–∞–≥—Ä—É–∑–∫–∏
    /// </summary>
    public class ModelDownloadButtonVisibilityChangedEventArgs : EventArgs
    {
        public bool IsVisible { get; }

        public ModelDownloadButtonVisibilityChangedEventArgs(bool isVisible)
        {
            IsVisible = isVisible;
        }
    }
    #endregion
}