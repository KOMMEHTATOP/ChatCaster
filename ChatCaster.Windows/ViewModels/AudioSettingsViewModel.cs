using ChatCaster.Core.Models;
using ChatCaster.Core.Services.Audio;
using ChatCaster.Core.Services.Core;
using ChatCaster.Windows.ViewModels.Base;
using ChatCaster.SpeechRecognition.Whisper.Constants;
using CommunityToolkit.Mvvm.ComponentModel;
using CommunityToolkit.Mvvm.Input;
using Serilog;
using System.Collections.ObjectModel;

namespace ChatCaster.Windows.ViewModels;

public partial class AudioSettingsViewModel : BaseSettingsViewModel
{
    #region Private Fields

    private readonly ISpeechRecognitionService _speechRecognitionService;
    private readonly IAudioCaptureService _audioService;

    #endregion

    #region Observable Properties with Immediate Apply

    [ObservableProperty]
    private List<AudioDevice> _availableDevices = new();

    [ObservableProperty]
    private AudioDevice? _selectedDevice;

    [ObservableProperty]
    private WhisperModelItem? _selectedModel;

    [ObservableProperty]
    private string _selectedLanguage = "ru";

    [ObservableProperty]
    private int _maxRecordingSeconds = 10;

    [ObservableProperty]
    private int _selectedSampleRate = 16000;

    [ObservableProperty]
    private bool _isModelReady = false;

    [ObservableProperty]
    private bool _isModelNotReady = true;

    [ObservableProperty]
    private bool _isModelDownloading = false;

    [ObservableProperty]
    private string _modelStatusText = "–ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞";

    [ObservableProperty]
    private string _modelStatusColor = "#4caf50";

    #endregion

    #region Public Properties for UI Binding

    /// <summary>
    /// –ö–æ–ª–ª–µ–∫—Ü–∏—è –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π Whisper –¥–ª—è –ø—Ä–∏–≤—è–∑–∫–∏ –∫ UI
    /// </summary>
    public ObservableCollection<WhisperModelItem> AvailableModels { get; } = new();

    /// <summary>
    /// –î–æ—Å—Ç—É–ø–Ω—ã–µ —á–∞—Å—Ç–æ—Ç—ã –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏
    /// </summary>
    public List<int> AvailableSampleRates { get; } = new()
    {
        8000,
        16000,
        22050,
        44100,
        48000
    };

    /// <summary>
    /// –¢–æ–ø-5 —è–∑—ã–∫–æ–≤ Steam –¥–ª—è Whisper
    /// </summary>
    public List<LanguageItem> AvailableLanguages { get; } = new()
    {
        new LanguageItem { Code = "en", Name = "üá∫üá∏ English" },
        new LanguageItem { Code = "zh", Name = "üá®üá≥ ÁÆÄ‰Ωì‰∏≠Êñá" },
        new LanguageItem { Code = "ru", Name = "üá∑üá∫ –†—É—Å—Å–∫–∏–π" },
        new LanguageItem { Code = "es", Name = "üá™üá∏ Espa√±ol" },
        new LanguageItem { Code = "de", Name = "üá©üá™ Deutsch" }
    };

    #endregion

    #region Commands

    [RelayCommand]
    private async Task DownloadModel()
    {
        await DownloadModelAsync();
    }

    #endregion

    #region Constructor

    public AudioSettingsViewModel(
        IConfigurationService configurationService,
        AppConfig currentConfig,
        ISpeechRecognitionService speechRecognitionService)
        : base(configurationService, currentConfig)
    {
        Log.Information("[AudioSettingsViewModel] –ö–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä –≤—ã–∑–≤–∞–Ω (Whisper –º–æ–¥—É–ª—å)");

        _speechRecognitionService = speechRecognitionService ?? throw new ArgumentNullException(nameof(speechRecognitionService));
        
        // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏
        InitializeAvailableModels();

        Log.Information("[AudioSettingsViewModel] —Å–æ–∑–¥–∞–Ω —Å –Ω–æ–≤—ã–º Whisper –º–æ–¥—É–ª–µ–º");
    }

    // ‚úÖ –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ô –ö–û–ù–°–¢–†–£–ö–¢–û–† —Å AudioService
    public AudioSettingsViewModel(
        IConfigurationService configurationService,
        AppConfig currentConfig,
        ISpeechRecognitionService speechRecognitionService,
        IAudioCaptureService audioService)
        : this(configurationService, currentConfig, speechRecognitionService)
    {
        _audioService = audioService ?? throw new ArgumentNullException(nameof(audioService));
    }

    #endregion

    #region Observable Property Changed Handlers - IMMEDIATE APPLY

    /// <summary>
    /// Immediate Apply: –í—ã–±—Ä–∞–Ω–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –∏–∑–º–µ–Ω–µ–Ω–æ
    /// </summary>
    partial void OnSelectedDeviceChanged(AudioDevice? value)
    {
        if (IsLoadingUI) return;

        Log.Information("üîÑ –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –∏–∑–º–µ–Ω–µ–Ω–æ: {DeviceName} ({DeviceId})",
            value?.Name ?? "–Ω–µ –≤—ã–±—Ä–∞–Ω–æ", value?.Id ?? "");

        // Immediate Apply
        _ = OnUISettingChangedAsync();
    }

    /// <summary>
    /// Immediate Apply: –ú–æ–¥–µ–ª—å Whisper –∏–∑–º–µ–Ω–µ–Ω–∞
    /// </summary>
    partial void OnSelectedModelChanged(WhisperModelItem? value)
    {
        if (IsLoadingUI) return;

        Log.Information("üîÑ –ú–æ–¥–µ–ª—å –∏–∑–º–µ–Ω–µ–Ω–∞: {Model} ({DisplayName})",
            value?.ModelSize, value?.DisplayName);

        // –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏ –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏
        _ = Task.Run(async () =>
        {
            try
            {
                await CheckModelStatusAsync();
            }
            catch (Exception ex)
            {
                Log.Error(ex, "–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç–∞—Ç—É—Å–∞ –º–æ–¥–µ–ª–∏ –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏");
            }
        });

        // Immediate Apply
        _ = OnUISettingChangedAsync();
    }

    /// <summary>
    /// Immediate Apply: –Ø–∑—ã–∫ –∏–∑–º–µ–Ω–µ–Ω
    /// </summary>
    partial void OnSelectedLanguageChanged(string value)
    {
        if (IsLoadingUI) return;

        Log.Information("üîÑ –Ø–∑—ã–∫ –∏–∑–º–µ–Ω–µ–Ω: {Language}", value);

        // Immediate Apply
        _ = OnUISettingChangedAsync();
    }

    /// <summary>
    /// Immediate Apply: –í—Ä–µ–º—è –∑–∞–ø–∏—Å–∏ –∏–∑–º–µ–Ω–µ–Ω–æ
    /// </summary>
    partial void OnMaxRecordingSecondsChanged(int value)
    {
        if (IsLoadingUI) return;

        Log.Information("üîÑ –í—Ä–µ–º—è –∑–∞–ø–∏—Å–∏ –∏–∑–º–µ–Ω–µ–Ω–æ: {Seconds}—Å", value);

        // Immediate Apply - –û–°–ù–û–í–ù–ê–Ø –§–ò–ß–ê!
        _ = OnUISettingChangedAsync();
    }

    /// <summary>
    /// Immediate Apply: –ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏ –∏–∑–º–µ–Ω–µ–Ω–∞
    /// </summary>
    partial void OnSelectedSampleRateChanged(int value)
    {
        if (IsLoadingUI) return;

        Log.Information("üîÑ –ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏ –∏–∑–º–µ–Ω–µ–Ω–∞: {SampleRate}Hz", value);

        // Immediate Apply
        _ = OnUISettingChangedAsync();
    }

    #endregion

    #region BaseSettingsViewModel Implementation

    protected override async Task LoadPageSpecificSettingsAsync()
    {
        Log.Information("[–î–ò–ê–ì–ù–û–°–¢–ò–ö–ê] LoadPageSpecificSettingsAsync –ù–ê–ß–ê–¢");

        try
        {
            Log.Information("[–î–ò–ê–ì–ù–û–°–¢–ò–ö–ê] –í—ã–∑—ã–≤–∞–µ–º LoadAudioDevicesAsync()");
            await LoadAudioDevicesAsync();
            Log.Information("[–î–ò–ê–ì–ù–û–°–¢–ò–ö–ê] LoadAudioDevicesAsync –ó–ê–í–ï–†–®–ï–ù");

            Log.Information("[–î–ò–ê–ì–ù–û–°–¢–ò–ö–ê] –ü–ï–†–ï–î ApplyConfigToProperties()");
            ApplyConfigToProperties();
            Log.Information("[–î–ò–ê–ì–ù–û–°–¢–ò–ö–ê] –ü–û–°–õ–ï ApplyConfigToProperties()");

            // –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å –º–æ–¥–µ–ª–∏ –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–∞—Å—Ç—Ä–æ–µ–∫
            Log.Information("[–î–ò–ê–ì–ù–û–°–¢–ò–ö–ê] –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å –º–æ–¥–µ–ª–∏...");
            await CheckModelStatusAsync();
            Log.Information("[–î–ò–ê–ì–ù–û–°–¢–ò–ö–ê] –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ –º–æ–¥–µ–ª–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∞");

            Log.Information("[–î–ò–ê–ì–ù–û–°–¢–ò–ö–ê] LoadPageSpecificSettingsAsync –ó–ê–í–ï–†–®–ï–ù");
        }
        catch (Exception ex)
        {
            Log.Error(ex, "[–î–ò–ê–ì–ù–û–°–¢–ò–ö–ê] –ò–°–ö–õ–Æ–ß–ï–ù–ò–ï –≤ LoadPageSpecificSettingsAsync");
        }
    }

    protected override async Task ApplySettingsToConfigAsync(AppConfig config)
    {
        try
        {
            Log.Information("[AudioSettingsViewModel] –ü—Ä–∏–º–µ–Ω—è–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∫ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏...");

            // –ü—Ä–∏–º–µ–Ω—è–µ–º –∞—É–¥–∏–æ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
            config.Audio.SelectedDeviceId = SelectedDevice?.Id ?? "";
            config.Audio.SampleRate = SelectedSampleRate;
            config.Audio.MaxRecordingSeconds = MaxRecordingSeconds;

            // –ü—Ä–∏–º–µ–Ω—è–µ–º Whisper –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —á–µ—Ä–µ–∑ EngineSettings
            config.SpeechRecognition.Language = SelectedLanguage;
            config.SpeechRecognition.EngineSettings["ModelSize"] = SelectedModel?.ModelSize ?? WhisperConstants.ModelSizes.Base;

            Log.Information(
                "[AudioSettingsViewModel] –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω—ã: Device={DeviceId}, Model={Model}, Language={Language}, Time={Seconds}s",
                config.Audio.SelectedDeviceId, SelectedModel?.ModelSize, config.SpeechRecognition.Language,
                config.Audio.MaxRecordingSeconds);
        }
        catch (Exception ex)
        {
            Log.Error(ex, "[AudioSettingsViewModel] –û—à–∏–±–∫–∞ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–∫ –∫ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏");
            throw;
        }
    }
    
    protected override async Task ApplySettingsToServicesAsync()
    {
        try
        {
            Log.Information("[AudioSettingsViewModel] –ü—Ä–∏–º–µ–Ω—è–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∫ —Å–µ—Ä–≤–∏—Å–∞–º...");

            // –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∞–∫—Ç–∏–≤–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
            if (SelectedDevice != null)
            {
                await _audioService.SetActiveDeviceAsync(SelectedDevice.Id);
                Log.Information("[AudioSettingsViewModel] –ê–∫—Ç–∏–≤–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ: {DeviceName}",
                    SelectedDevice.Name);
            }

            // –ü–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º Whisper –º–æ–¥—É–ª—å –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –∏–∑–º–µ–Ω–µ–Ω–∞
            if (SelectedModel != null)
            {
                var speechConfig = _currentConfig.SpeechRecognition;
                speechConfig.EngineSettings["ModelSize"] = SelectedModel.ModelSize;
                
                var result = await _speechRecognitionService.ReloadConfigAsync(speechConfig);
                Log.Information("[AudioSettingsViewModel] Whisper –º–æ–¥—É–ª—å –ø–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω: {Success}, –ú–æ–¥–µ–ª—å: {Model}",
                    result, SelectedModel.DisplayName);
            }

            Log.Information("[AudioSettingsViewModel] –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω—ã –∫ —Å–µ—Ä–≤–∏—Å–∞–º");
        }
        catch (Exception ex)
        {
            Log.Error(ex, "[AudioSettingsViewModel] –û—à–∏–±–∫–∞ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–∫ –∫ —Å–µ—Ä–≤–∏—Å–∞–º");
            throw;
        }
    }

    public override void SubscribeToUIEvents()
    {
        // Observable —Å–≤–æ–π—Å—Ç–≤–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Ä–∞–±–æ—Ç–∞—é—Ç —á–µ—Ä–µ–∑ XAML –ø—Ä–∏–≤—è–∑–∫–∏
        Log.Information("[AudioSettingsViewModel] UI —Å–æ–±—ã—Ç–∏—è –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è —á–µ—Ä–µ–∑ XAML –ø—Ä–∏–≤—è–∑–∫–∏");
    }

    protected override void CleanupPageSpecific()
    {
        try
        {
            // –û—á–∏—Å—Ç–∫–∞ –µ—Å–ª–∏ –Ω—É–∂–Ω–∞
            Log.Debug("[AudioSettingsViewModel] –û—á–∏—Å—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞");
        }
        catch (Exception ex)
        {
            Log.Error(ex, "[AudioSettingsViewModel] –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏");
        }
    }

    #endregion

    #region Public Methods

    /// <summary>
    /// –ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å Whisper
    /// </summary>
    public async Task DownloadModelAsync()
    {
        try
        {
            if (SelectedModel == null)
            {
                Log.Warning("–ú–æ–¥–µ–ª—å –Ω–µ –≤—ã–±—Ä–∞–Ω–∞ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏");
                return;
            }

            Log.Information("–ù–∞—á–∏–Ω–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É –º–æ–¥–µ–ª–∏: {Model}", SelectedModel.ModelSize);
            
            UpdateModelStatus("–ó–∞–≥—Ä—É–∑–∫–∞...", "#ff9800", ModelState.Downloading);

            // –ó–∞–≥—Ä—É–∑–∫–∞ —á–µ—Ä–µ–∑ –Ω–æ–≤—ã–π Whisper –º–æ–¥—É–ª—å
            // –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥—É–ª—å
            var speechConfig = _currentConfig.SpeechRecognition;
            speechConfig.EngineSettings["ModelSize"] = SelectedModel.ModelSize;
            
            var result = await _speechRecognitionService.ReloadConfigAsync(speechConfig);
            
            if (result)
            {
                UpdateModelStatus("–ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞", "#4caf50", ModelState.Ready);
                Log.Information("–ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {Model}", SelectedModel.ModelSize);
            }
            else
            {
                UpdateModelStatus("–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏", "#f44336", ModelState.Error);
                Log.Error("–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {Model}", SelectedModel.ModelSize);
            }
        }
        catch (Exception ex)
        {
            UpdateModelStatus("–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏", "#f44336", ModelState.Error);
            Log.Error(ex, "–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏");
        }
    }

    #endregion

    #region Private Methods

    /// <summary>
    /// –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ Whisper
    /// </summary>
    private void InitializeAvailableModels()
    {
        AvailableModels.Clear();
        
        foreach (var modelSize in WhisperConstants.ModelSizes.All)
        {
            AvailableModels.Add(new WhisperModelItem
            {
                ModelSize = modelSize,
                DisplayName = GetModelDisplayName(modelSize),
                Description = GetModelDescription(modelSize)
            });
        }
        
        Log.Information("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {Count} –º–æ–¥–µ–ª–µ–π Whisper", AvailableModels.Count);
    }

    /// <summary>
    /// –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∞—É–¥–∏–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤
    /// </summary>
    private async Task LoadAudioDevicesAsync()
    {
        try
        {
            var devices = await _audioService.GetAvailableDevicesAsync();
            AvailableDevices = devices.ToList();

            Log.Information("[AudioSettingsViewModel] –ó–∞–≥—Ä—É–∂–µ–Ω–æ {Count} –∞—É–¥–∏–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤", AvailableDevices.Count);
        }
        catch (Exception ex)
        {
            Log.Error(ex, "[AudioSettingsViewModel] –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∞—É–¥–∏–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤");
            AvailableDevices = new List<AudioDevice>();
        }
    }

    /// <summary>
    /// –ü—Ä–∏–º–µ–Ω—è–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞ –∫ Observable —Å–≤–æ–π—Å—Ç–≤–∞–º
    /// </summary>
    private void ApplyConfigToProperties()
    {
        try
        {
            Log.Information("[AudioSettingsViewModel] –ü—Ä–∏–º–µ–Ω—è–µ–º –∫–æ–Ω—Ñ–∏–≥ –∫ —Å–≤–æ–π—Å—Ç–≤–∞–º...");

            // –í—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–∫–ª—é—á–∞–µ–º IsLoadingUI —á—Ç–æ–±—ã –æ–±–Ω–æ–≤–∏—Ç—å —Å–≤–æ–π—Å—Ç–≤–∞
            var wasLoading = IsLoadingUI;
            IsLoadingUI = false;

            // –ü—Ä–∏–º–µ–Ω—è–µ–º –∞—É–¥–∏–æ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
            MaxRecordingSeconds = _currentConfig.Audio.MaxRecordingSeconds;
            SelectedSampleRate = _currentConfig.Audio.SampleRate;

            // –ù–∞—Ö–æ–¥–∏–º –∏ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤—ã–±—Ä–∞–Ω–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
            if (!string.IsNullOrEmpty(_currentConfig.Audio.SelectedDeviceId))
            {
                SelectedDevice = AvailableDevices.FirstOrDefault(d => d.Id == _currentConfig.Audio.SelectedDeviceId);
                Log.Information("[AudioSettingsViewModel] –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞: {DeviceId} -> {DeviceName}", 
                    _currentConfig.Audio.SelectedDeviceId, SelectedDevice?.Name ?? "–Ω–µ –Ω–∞–π–¥–µ–Ω–æ");
            }

            // –ï—Å–ª–∏ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –ò–õ–ò –ø—É—Å—Ç–æ–µ - –∞–≤—Ç–æ–≤—ã–±–æ—Ä
            if (SelectedDevice == null && AvailableDevices.Any())
            {
                SelectedDevice = AvailableDevices.FirstOrDefault(d => d.IsDefault) 
                                 ?? AvailableDevices.First();
                Log.Information("–ê–≤—Ç–æ–≤—ã–±–æ—Ä —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞: {DeviceName}", SelectedDevice.Name);
            }

            // –ü—Ä–∏–º–µ–Ω—è–µ–º Whisper –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ EngineSettings
            var modelSize = _currentConfig.SpeechRecognition.EngineSettings.TryGetValue("ModelSize", out var modelObj) 
                ? modelObj?.ToString() 
                : WhisperConstants.ModelSizes.Base;

            SelectedModel = AvailableModels.FirstOrDefault(m => m.ModelSize == modelSize)
                           ?? AvailableModels.First(); // Fallback –Ω–∞ –ø–µ—Ä–≤—É—é –º–æ–¥–µ–ª—å

            SelectedLanguage = _currentConfig.SpeechRecognition.Language;

            // –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ñ–ª–∞–≥ IsLoadingUI
            IsLoadingUI = wasLoading;

            Log.Information(
                "[AudioSettingsViewModel] –ö–æ–Ω—Ñ–∏–≥ –ø—Ä–∏–º–µ–Ω–µ–Ω: Device={DeviceName}, Model={Model}, Language={Language}, Time={Seconds}s",
                SelectedDevice?.Name, SelectedModel?.DisplayName, SelectedLanguage, MaxRecordingSeconds);
        }
        catch (Exception ex)
        {
            Log.Error(ex, "[AudioSettingsViewModel] –û—à–∏–±–∫–∞ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥–∞ –∫ —Å–≤–æ–π—Å—Ç–≤–∞–º");
        }
    }

    /// <summary>
    /// –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—Ç–∞—Ç—É—Å –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
    /// </summary>
    private async Task CheckModelStatusAsync()
    {
        try
        {
            if (SelectedModel == null)
            {
                UpdateModelStatus("–ú–æ–¥–µ–ª—å –Ω–µ –≤—ã–±—Ä–∞–Ω–∞", "#f44336", ModelState.Error);
                return;
            }

            // –ü—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ ISpeechRecognitionService
            if (_speechRecognitionService.IsInitialized)
            {
                UpdateModelStatus("–ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞", "#4caf50", ModelState.Ready);
            }
            else
            {
                UpdateModelStatus("–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞", "#ff9800", ModelState.NotDownloaded);
            }

            await Task.CompletedTask;
        }
        catch (Exception ex)
        {
            Log.Error(ex, "–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç–∞—Ç—É—Å–∞ –º–æ–¥–µ–ª–∏");
            UpdateModelStatus("–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏", "#f44336", ModelState.Error);
        }
    }

    /// <summary>
    /// –û–±–Ω–æ–≤–ª—è–µ—Ç —Å—Ç–∞—Ç—É—Å –º–æ–¥–µ–ª–∏ –¥–ª—è UI
    /// </summary>
    public void UpdateModelStatus(string status, string color, ModelState state)
    {
        ModelStatusText = status;
        ModelStatusColor = color;
        
        // –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏—è –¥–ª—è –≤–∏–¥–∏–º–æ—Å—Ç–∏ —ç–ª–µ–º–µ–Ω—Ç–æ–≤
        IsModelReady = state == ModelState.Ready;
        IsModelNotReady = state == ModelState.NotDownloaded;
        IsModelDownloading = state == ModelState.Downloading;
        
        Log.Information("UI —Å—Ç–∞—Ç—É—Å –º–æ–¥–µ–ª–∏ –æ–±–Ω–æ–≤–ª–µ–Ω: {Status}, —Å–æ—Å—Ç–æ—è–Ω–∏–µ: {State}", status, state);
    }

    private string GetModelDisplayName(string modelSize)
    {
        return modelSize switch
        {
            WhisperConstants.ModelSizes.Tiny => "Tiny (–±—ã—Å—Ç—Ä–∞—è)",
            WhisperConstants.ModelSizes.Base => "Base (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è)",
            WhisperConstants.ModelSizes.Small => "Small (—Ö–æ—Ä–æ—à–∞—è)",
            WhisperConstants.ModelSizes.Medium => "Medium (—Ç–æ—á–Ω–∞—è)",
            WhisperConstants.ModelSizes.Large => "Large (–æ—á–µ–Ω—å —Ç–æ—á–Ω–∞—è)",
            _ => modelSize
        };
    }

    private string GetModelDescription(string modelSize)
    {
        return modelSize switch
        {
            WhisperConstants.ModelSizes.Tiny => "~39 MB, –±—ã—Å—Ç—Ä–æ",
            WhisperConstants.ModelSizes.Base => "~142 MB, –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ",
            WhisperConstants.ModelSizes.Small => "~466 MB, —Ö–æ—Ä–æ—à–æ",
            WhisperConstants.ModelSizes.Medium => "~1.5 GB, —Ç–æ—á–Ω–æ",
            WhisperConstants.ModelSizes.Large => "~3.0 GB, –æ—á–µ–Ω—å —Ç–æ—á–Ω–æ",
            _ => "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –º–æ–¥–µ–ª—å"
        };
    }

    #endregion

    #region Helper Classes

    /// <summary>
    /// –°–æ—Å—Ç–æ—è–Ω–∏—è –º–æ–¥–µ–ª–∏ –¥–ª—è UI
    /// </summary>
    public enum ModelState
    {
        Ready,
        NotDownloaded,
        Downloading,
        Error
    }

    public class LanguageItem
    {
        public string Code { get; set; } = "";
        public string Name { get; set; } = "";
    }

    public class WhisperModelItem
    {
        public string ModelSize { get; set; } = "";
        public string DisplayName { get; set; } = "";
        public string Description { get; set; } = "";
    }

    #endregion
}