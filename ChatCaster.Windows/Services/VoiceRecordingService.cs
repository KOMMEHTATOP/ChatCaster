using ChatCaster.Core.Models;
using ChatCaster.Core.Events;
using ChatCaster.Core.Services.Audio;
using ChatCaster.Core.Services.Core;
using Serilog;
using System.Timers;

namespace ChatCaster.Windows.Services;

/// <summary>
/// –ì–ª–∞–≤–Ω—ã–π —Å–µ—Ä–≤–∏—Å —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∑–∞–ø–∏—Å—å—é –≥–æ–ª–æ—Å–∞
/// –ö–æ–æ—Ä–¥–∏–Ω–∏—Ä—É–µ—Ç —Ä–∞–±–æ—Ç—É AudioCaptureService –∏ SpeechRecognitionService
/// </summary>
public class VoiceRecordingService : IVoiceRecordingService, IDisposable
{
    public event EventHandler<RecordingStatusChangedEvent>? StatusChanged;
    public event EventHandler<VoiceRecognitionCompletedEvent>? RecognitionCompleted;

    private readonly IAudioCaptureService _audioCaptureService;
    private readonly ISpeechRecognitionService _speechRecognitionService;
    private readonly IConfigurationService _configurationService;

    private RecordingState _currentState = new RecordingState();
    private readonly List<byte> _recordingBuffer = new();
    private System.Timers.Timer? _recordingTimer;
    private readonly object _stateLock = new object();
    private bool _isDisposed = false;

    public RecordingState CurrentState
    {
        get
        {
            lock (_stateLock)
            {
                return _currentState;
            }
        }
        private set
        {
            lock (_stateLock)
            {
                if (_currentState.Status != value.Status)
                {
                    var oldStatus = _currentState.Status;
                    _currentState = value;
                    Log.Information($"üîÑ –°–æ—Å—Ç–æ—è–Ω–∏–µ –∑–∞–ø–∏—Å–∏: {oldStatus} ‚Üí {value.Status}");

                    StatusChanged?.Invoke(this, new RecordingStatusChangedEvent
                    {
                        OldStatus = oldStatus, NewStatus = value.Status, Reason = null // –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ø—Ä–∏—á–∏–Ω—É –ø–æ–∑–∂–µ
                    });
                }
            }
        }
    }

    public bool IsRecording => CurrentState.Status == RecordingStatus.Recording;

    public VoiceRecordingService(
        IAudioCaptureService audioCaptureService,
        ISpeechRecognitionService speechRecognitionService,
        IConfigurationService configurationService)
    {
        _audioCaptureService = audioCaptureService ?? throw new ArgumentNullException(nameof(audioCaptureService));
        _speechRecognitionService =
            speechRecognitionService ?? throw new ArgumentNullException(nameof(speechRecognitionService));
        _configurationService = configurationService ?? throw new ArgumentNullException(nameof(configurationService));

        // –ü–æ–¥–ø–∏—Å—ã–≤–∞–µ–º—Å—è –Ω–∞ —Å–æ–±—ã—Ç–∏—è –∞—É–¥–∏–æ –∑–∞—Ö–≤–∞—Ç–∞
        _audioCaptureService.AudioDataReceived += OnAudioDataReceived;
    }
    

    public async Task<bool> StartRecordingAsync(CancellationToken cancellationToken = default)
    {
        try
        {
            if (IsRecording)
            {
                Log.Information("üìù –ó–∞–ø–∏—Å—å —É–∂–µ –∏–¥–µ—Ç, –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º");
                return false;
            }

            Log.Information("üé§ –ù–∞—á–∏–Ω–∞–µ–º –∑–∞–ø–∏—Å—å...");
            CurrentState = new RecordingState
            {
                Status = RecordingStatus.Recording, StartTime = DateTime.Now
            };

            // –û—á–∏—â–∞–µ–º –±—É—Ñ–µ—Ä
            lock (_recordingBuffer)
            {
                _recordingBuffer.Clear();
            }

            // –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
            var config = _configurationService.CurrentConfig;
            var audioConfig = config.Audio;
            var maxSeconds = audioConfig.MaxRecordingSeconds;

            // –ó–∞–ø—É—Å–∫–∞–µ–º –∑–∞—Ö–≤–∞—Ç –∞—É–¥–∏–æ –µ—Å–ª–∏ –Ω–µ –∑–∞–ø—É—â–µ–Ω
            if (!_audioCaptureService.IsCapturing)
            {
                bool captureStarted = await _audioCaptureService.StartCaptureAsync(audioConfig);

                if (!captureStarted)
                {
                    Log.Information("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø—É—Å—Ç–∏—Ç—å –∑–∞—Ö–≤–∞—Ç –∞—É–¥–∏–æ");
                    CurrentState = new RecordingState
                    {
                        Status = RecordingStatus.Error, ErrorMessage = "–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø—É—Å—Ç–∏—Ç—å –∑–∞—Ö–≤–∞—Ç –∞—É–¥–∏–æ"
                    };
                    return false;
                }
            }

            // –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–∞–π–º–µ—Ä –∞–≤—Ç–æ–æ—Å—Ç–∞–Ω–æ–≤–∫–∏
            _recordingTimer = new System.Timers.Timer(maxSeconds * 1000);
            _recordingTimer.Elapsed += OnRecordingTimerElapsed;
            _recordingTimer.AutoReset = false;
            _recordingTimer.Start();

            CurrentState = new RecordingState
            {
                Status = RecordingStatus.Recording, StartTime = DateTime.Now, Duration = TimeSpan.Zero
            };
            Log.Information($"‚úÖ –ó–∞–ø–∏—Å—å –Ω–∞—á–∞–ª–∞—Å—å (–º–∞–∫—Å. {maxSeconds} —Å–µ–∫)");

            return true;
        }
        catch (Exception ex)
        {
            Log.Information($"‚ùå –û—à–∏–±–∫–∞ –Ω–∞—á–∞–ª–∞ –∑–∞–ø–∏—Å–∏: {ex.Message}");
            CurrentState = new RecordingState
            {
                Status = RecordingStatus.Error, ErrorMessage = ex.Message
            };
            return false;
        }
    }

    public async Task<VoiceProcessingResult> StopRecordingAsync(CancellationToken cancellationToken = default)
    {
        try
        {
            if (!IsRecording)
            {
                Log.Information("üìù –ó–∞–ø–∏—Å—å –Ω–µ –∏–¥–µ—Ç, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç");
                return new VoiceProcessingResult
                {
                    Success = false, RecognizedText = "", ErrorMessage = "–ó–∞–ø–∏—Å—å –Ω–µ –±—ã–ª–∞ –∞–∫—Ç–∏–≤–Ω–∞"
                };
            }

            Log.Information("üõë –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–ø–∏—Å—å...");
            await _audioCaptureService.StopCaptureAsync();
            CurrentState = new RecordingState
            {
                Status = RecordingStatus.Processing
            };

            // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–∞–π–º–µ—Ä
            _recordingTimer?.Stop();
            _recordingTimer?.Dispose();
            _recordingTimer = null;

            // –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –±—É—Ñ–µ—Ä–∞
            byte[] audioData;

            lock (_recordingBuffer)
            {
                audioData = _recordingBuffer.ToArray();
                _recordingBuffer.Clear();
            }

            Log.Information($"üì§ –ü–æ–ª—É—á–µ–Ω–æ {audioData.Length} –±–∞–π—Ç –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è");

            if (audioData.Length == 0)
            {
                Log.Information("‚ùå –ù–µ—Ç –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è");
                CurrentState = new RecordingState
                {
                    Status = RecordingStatus.Idle
                };
                return new VoiceProcessingResult
                {
                    Success = false, RecognizedText = "", ErrorMessage = "–ù–µ—Ç –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã—Ö"
                };
            }

            // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ
            var result = await _speechRecognitionService.RecognizeAsync(audioData, cancellationToken);

            CurrentState = new RecordingState
            {
                Status = result.Success ? RecordingStatus.Completed : RecordingStatus.Error,
                LastRecognizedText = result.RecognizedText,
                ErrorMessage = result.ErrorMessage
            };

            // –£–≤–µ–¥–æ–º–ª—è–µ–º –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏
            RecognitionCompleted?.Invoke(this, new VoiceRecognitionCompletedEvent
            {
                Result = result, AudioDataSize = audioData.Length
            });

            if (result.Success && !string.IsNullOrEmpty(result.RecognizedText))
            {
                Log.Information($"‚úÖ –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: '{result.RecognizedText}'");
            }
            else
            {
                Log.Information($"‚ùå –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å: {result.ErrorMessage}");
            }

            return result;
        }
        catch (Exception ex)
        {
            Log.Information($"‚ùå –û—à–∏–±–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –∑–∞–ø–∏—Å–∏: {ex.Message}");
            CurrentState = new RecordingState
            {
                Status = RecordingStatus.Error, ErrorMessage = ex.Message
            };

            return new VoiceProcessingResult
            {
                Success = false, RecognizedText = "", ErrorMessage = ex.Message
            };
        }
    }

    public async Task CancelRecordingAsync()
    {
        try
        {
            if (!IsRecording)
            {
                return;
            }

            Log.Information("‚ùå –û—Ç–º–µ–Ω—è–µ–º –∑–∞–ø–∏—Å—å...");
            await _audioCaptureService.StopCaptureAsync();

            // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–∞–π–º–µ—Ä
            _recordingTimer?.Stop();
            _recordingTimer?.Dispose();
            _recordingTimer = null;

            // –û—á–∏—â–∞–µ–º –±—É—Ñ–µ—Ä
            lock (_recordingBuffer)
            {
                _recordingBuffer.Clear();
            }

            CurrentState = new RecordingState
            {
                Status = RecordingStatus.Cancelled
            };
            Log.Information("‚úÖ –ó–∞–ø–∏—Å—å –æ—Ç–º–µ–Ω–µ–Ω–∞");
        }
        catch (Exception ex)
        {
            Log.Information($"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–º–µ–Ω—ã –∑–∞–ø–∏—Å–∏: {ex.Message}");
            CurrentState = new RecordingState
            {
                Status = RecordingStatus.Error, ErrorMessage = ex.Message
            };
        }
    }

    public async Task<bool> TestMicrophoneAsync()
    {
        try
        {
            Log.Information("üîç –¢–µ—Å—Ç–∏—Ä—É–µ–º –º–∏–∫—Ä–æ—Ñ–æ–Ω...");
            return await _audioCaptureService.TestMicrophoneAsync();
        }
        catch (Exception ex)
        {
            Log.Information($"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞: {ex.Message}");
            return false;
        }
    }

    public async Task<VoiceProcessingResult> ProcessAudioDataAsync(byte[] audioData,
        CancellationToken cancellationToken = default)
    {
        try
        {
            Log.Information($"üì§ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º {audioData.Length} –±–∞–π—Ç –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã—Ö");
            return await _speechRecognitionService.RecognizeAsync(audioData, cancellationToken);
        }
        catch (Exception ex)
        {
            Log.Information($"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ: {ex.Message}");
            return new VoiceProcessingResult
            {
                Success = false, RecognizedText = "", ErrorMessage = ex.Message
            };
        }
    }

    private void OnAudioDataReceived(object? sender, byte[] audioData)
    {
        try
        {
            // –î–æ–±–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ –±—É—Ñ–µ—Ä —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∏–¥–µ—Ç –∑–∞–ø–∏—Å—å
            if (IsRecording)
            {
                lock (_recordingBuffer)
                {
                    _recordingBuffer.AddRange(audioData);
                }
            }
        }
        catch (Exception ex)
        {
            Log.Information($"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã—Ö: {ex.Message}");
        }
    }

    private async void OnRecordingTimerElapsed(object? sender, ElapsedEventArgs e)
    {
        try
        {
            var config = _configurationService.CurrentConfig;
            var maxSeconds = config.Audio.MaxRecordingSeconds;
            Log.Information($"‚è∞ –í—Ä–µ–º—è –∑–∞–ø–∏—Å–∏ ({maxSeconds} —Å–µ–∫) –∏—Å—Ç–µ–∫–ª–æ, –∞–≤—Ç–æ–æ—Å—Ç–∞–Ω–æ–≤–∫–∞");

            await StopRecordingAsync();
        }
        catch (Exception ex)
        {
            Log.Information($"‚ùå –û—à–∏–±–∫–∞ –∞–≤—Ç–æ–æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –∑–∞–ø–∏—Å–∏: {ex.Message}");
        }
    }

    public void Dispose()
    {
        if (!_isDisposed)
        {
            _recordingTimer?.Stop();
            _recordingTimer?.Dispose();
            _recordingTimer = null;

            // –û—Ç–ø–∏—Å—ã–≤–∞–µ–º—Å—è –æ—Ç —Å–æ–±—ã—Ç–∏–π
            _audioCaptureService.AudioDataReceived -= OnAudioDataReceived;

            lock (_recordingBuffer)
            {
                _recordingBuffer.Clear();
            }

            _isDisposed = true;
        }
    }
}
