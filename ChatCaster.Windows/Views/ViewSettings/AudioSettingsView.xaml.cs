using System.Windows;
using System.Windows.Controls;
using System.Windows.Media;
using ChatCaster.Core.Models;
using ChatCaster.Windows.Services;
using ChatCaster.Windows.ViewModels;
using ChatCaster.Windows.ViewModels.Settings;
using ChatCaster.Windows.ViewModels.Settings.Speech;
using Serilog;
using AudioSettingsViewModel = ChatCaster.Windows.ViewModels.AudioSettingsViewModel;

namespace ChatCaster.Windows.Views.ViewSettings;

public partial class AudioSettingsView 
{
    private readonly AudioCaptureService? _audioCaptureService;
    private readonly SpeechRecognitionService? _speechRecognitionService;
    private readonly ConfigurationService? _configService;
    private readonly ServiceContext? _serviceContext;

    private bool _isTestingMicrophone = false;
    private bool _isDownloadingModel = false;

    public AudioSettingsView()
    {
        InitializeComponent();
    }

    // –ö–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä —Å —Å–µ—Ä–≤–∏—Å–∞–º–∏
    public AudioSettingsView(AudioCaptureService audioCaptureService, 
                            SpeechRecognitionService speechRecognitionService, 
                            ConfigurationService configService, 
                            ServiceContext serviceContext) : this()
    {
        _audioCaptureService = audioCaptureService;
        _speechRecognitionService = speechRecognitionService;
        _configService = configService;
        _serviceContext = serviceContext;
        
        Log.Debug("AudioSettingsView –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Å —Å–µ—Ä–≤–∏—Å–∞–º–∏");
    }

    // ‚úÖ –ù–û–í–´–ô –ú–ï–¢–û–î: –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç ViewModel –∏ —Å–≤—è–∑—ã–≤–∞–µ—Ç UI —ç–ª–µ–º–µ–Ω—Ç—ã
    public void SetViewModel(AudioSettingsViewModel viewModel)
    {
        try
        {
            Log.Information("=== –£–°–¢–ê–ù–û–í–ö–ê VIEWMODEL ===");
            
            // –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º DataContext
            DataContext = viewModel;
            
            // –°–≤—è–∑—ã–≤–∞–µ–º UI —ç–ª–µ–º–µ–Ω—Ç—ã —Å ViewModel
            viewModel.SetUIControls(
                MicrophoneComboBox,
                WhisperModelComboBox,
                LanguageComboBox,
                MaxDurationSlider
            );
            
            Log.Information("ViewModel —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏ UI —ç–ª–µ–º–µ–Ω—Ç—ã —Å–≤—è–∑–∞–Ω—ã");
            
            // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º ViewModel
            _ = viewModel.InitializeAsync();
        }
        catch (Exception ex)
        {
            Log.Error(ex, "–û—à–∏–±–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ ViewModel");
        }
    }
    
    private void TestMicrophoneButton_Click(object sender, RoutedEventArgs e)
    {
        if (_isTestingMicrophone || _audioCaptureService == null) return;
        _ = HandleTestMicrophoneAsync();
    }

    private async Task HandleTestMicrophoneAsync()
    {
        try
        {
            _isTestingMicrophone = true;
            TestMicrophoneButton.IsEnabled = false;
            UpdateMicrophoneStatus("–¢–µ—Å—Ç–∏—Ä—É–µ—Ç—Å—è...", "#ff9800");

            Log.Information("üîÑ –ù–∞—á–∏–Ω–∞–µ–º —Ç–µ—Å—Ç –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞");

            // –ü–æ–ª—É—á–∞–µ–º AudioDevice –≤–º–µ—Å—Ç–æ ComboBoxItem
            var selectedDevice = MicrophoneComboBox.SelectedItem as AudioDevice;
            if (selectedDevice != null)
            {
                Log.Information("–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∞–∫—Ç–∏–≤–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {DeviceId} ({DeviceName})", 
                    selectedDevice.Id, selectedDevice.Name);
            
                await _audioCaptureService!.SetActiveDeviceAsync(selectedDevice.Id);
            }
            else
            {
                Log.Warning("–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –Ω–µ –≤—ã–±—Ä–∞–Ω–æ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è");
                UpdateMicrophoneStatus("–í—ã–±–µ—Ä–∏—Ç–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ", "#ff9800");
                return;
            }

            // –¢–µ—Å—Ç–∏—Ä—É–µ–º –º–∏–∫—Ä–æ—Ñ–æ–Ω
            Log.Information("–ó–∞–ø—É—Å–∫–∞–µ–º TestMicrophoneAsync()");
            bool testResult = await _audioCaptureService!.TestMicrophoneAsync();

            if (testResult)
            {
                UpdateMicrophoneStatus("–ú–∏–∫—Ä–æ—Ñ–æ–Ω —Ä–∞–±–æ—Ç–∞–µ—Ç", "#4caf50");
                Log.Information("‚úÖ –¢–µ—Å—Ç –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ –ø—Ä–æ—à–µ–ª —É—Å–ø–µ—à–Ω–æ");
            }
            else
            {
                UpdateMicrophoneStatus("–ü—Ä–æ–±–ª–µ–º–∞ —Å –º–∏–∫—Ä–æ—Ñ–æ–Ω–æ–º", "#f44336");
                Log.Warning("‚ùå –¢–µ—Å—Ç –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ –Ω–µ –ø—Ä–æ—à–µ–ª");
            }
        }
        catch (Exception ex)
        {
            UpdateMicrophoneStatus($"–û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {ex.Message}", "#f44336");
            Log.Error(ex, "–û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞");
        }
        finally
        {
            _isTestingMicrophone = false;
            TestMicrophoneButton.IsEnabled = true;
        }
    }
    
    private void DownloadModelButton_Click(object sender, RoutedEventArgs e)
    {
        if (_isDownloadingModel || _speechRecognitionService == null) return;
        _ = HandleDownloadModelAsync();
    }

    private async Task HandleDownloadModelAsync()
    {
        try
        {
            _isDownloadingModel = true;
            DownloadModelButton.IsEnabled = false;

            Log.Information("üîÑ –ù–∞—á–∏–Ω–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É –º–æ–¥–µ–ª–∏");

            // ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü–æ–ª—É—á–∞–µ–º WhisperModelItem –≤–º–µ—Å—Ç–æ ComboBoxItem
            var selectedModel = WhisperModelComboBox.SelectedItem as WhisperModelItem;
            if (selectedModel != null)
            {
                var model = selectedModel.Model;
            
                UpdateModelStatus("–ù–∞—á–∏–Ω–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É...", "#ff9800");
                Log.Information("–ù–∞—á–∏–Ω–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É –º–æ–¥–µ–ª–∏ {Model} ({DisplayName})", model, selectedModel.DisplayName);

                // –ü–æ–¥–ø–∏—Å—ã–≤–∞–µ–º—Å—è –Ω–∞ —Å–æ–±—ã—Ç–∏—è –∑–∞–≥—Ä—É–∑–∫–∏
                _speechRecognitionService!.DownloadProgress += OnModelDownloadProgress;
                _speechRecognitionService.DownloadCompleted += OnModelDownloadCompleted;

                // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å (—ç—Ç–æ –∑–∞–ø—É—Å—Ç–∏—Ç –∑–∞–≥—Ä—É–∑–∫—É –µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
                var config = new WhisperConfig { Model = model };
                await _speechRecognitionService.InitializeAsync(config);
            }
            else
            {
                Log.Warning("–ú–æ–¥–µ–ª—å –Ω–µ –≤—ã–±—Ä–∞–Ω–∞ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏");
                UpdateModelStatus("–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å", "#ff9800");
                _isDownloadingModel = false;
                DownloadModelButton.IsEnabled = true;
            }
        }
        catch (Exception ex)
        {
            UpdateModelStatus($"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {ex.Message}", "#f44336");
            Log.Error(ex, "–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏");
            _isDownloadingModel = false;
            DownloadModelButton.IsEnabled = true;
        }
    }
    
    private void OnModelDownloadProgress(object? sender, Core.Events.ModelDownloadProgressEvent e)
    {
        Dispatcher.Invoke(() =>
        {
            UpdateModelStatus($"–ó–∞–≥—Ä—É–∑–∫–∞ {e.ProgressPercentage}%...", "#ff9800");
        });
    }

    private void OnModelDownloadCompleted(object? sender, Core.Events.ModelDownloadCompletedEvent e)
    {
        Dispatcher.Invoke(() =>
        {
            // –û—Ç–ø–∏—Å—ã–≤–∞–µ–º—Å—è –æ—Ç —Å–æ–±—ã—Ç–∏–π
            if (_speechRecognitionService != null)
            {
                _speechRecognitionService.DownloadProgress -= OnModelDownloadProgress;
                _speechRecognitionService.DownloadCompleted -= OnModelDownloadCompleted;
            }

            if (e.Success)
            {
                UpdateModelStatus("–ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞", "#4caf50");
                DownloadModelButton.Visibility = Visibility.Collapsed;
                Log.Information("–ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞");
            }
            else
            {
                UpdateModelStatus($"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e.ErrorMessage}", "#f44336");
                Log.Error("–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {Error}", e.ErrorMessage);
            }

            _isDownloadingModel = false;
            DownloadModelButton.IsEnabled = true;
        });
    }

    // ========== –£–¢–ò–õ–ò–¢–´ –û–°–¢–ê–Æ–¢–°–Ø ==========
    
    private void UpdateMicrophoneStatus(string text, string color)
    {
        MicrophoneStatusText.Text = text;
        MicrophoneStatusText.Foreground = new SolidColorBrush((Color)ColorConverter.ConvertFromString(color));
        MicrophoneStatusIcon.Fill = new SolidColorBrush((Color)ColorConverter.ConvertFromString(color));
    }

    private void UpdateModelStatus(string text, string color)
    {
        ModelStatusText.Text = text;
        ModelStatusText.Foreground = new SolidColorBrush((Color)ColorConverter.ConvertFromString(color));
        ModelStatusIcon.Fill = new SolidColorBrush((Color)ColorConverter.ConvertFromString(color));
    }

    private static string FormatFileSize(long bytes)
    {
        if (bytes >= 1_073_741_824) // GB
            return $"{bytes / 1_073_741_824.0:F1} GB";
        if (bytes >= 1_048_576) // MB
            return $"{bytes / 1_048_576.0:F0} MB";
        if (bytes >= 1024) // KB
            return $"{bytes / 1024.0:F0} KB";
        return $"{bytes} bytes";
    }

    // Cleanup –ø—Ä–∏ –≤—ã–≥—Ä—É–∑–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    private void Page_Unloaded(object sender, RoutedEventArgs e)
    {
        try
        {
            // –û—Ç–ø–∏—Å—ã–≤–∞–µ–º—Å—è –æ—Ç —Å–æ–±—ã—Ç–∏–π –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ –µ—Å–ª–∏ –ø–æ–¥–ø–∏—Å–∞–Ω—ã
            if (_speechRecognitionService != null)
            {
                _speechRecognitionService.DownloadProgress -= OnModelDownloadProgress;
                _speechRecognitionService.DownloadCompleted -= OnModelDownloadCompleted;
                Log.Debug("–û—Ç–ø–∏—Å–∞–ª–∏—Å—å –æ—Ç —Å–æ–±—ã—Ç–∏–π SpeechRecognitionService");
            }
            
            Log.Debug("AudioSettingsView –≤—ã–≥—Ä—É–∂–µ–Ω");
        }
        catch (Exception ex)
        {
            Log.Error(ex, "–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–≥—Ä—É–∑–∫–µ AudioSettingsView");
        }
    }
}