using ChatCaster.Core.Models;
using ChatCaster.Core.Events;
using ChatCaster.Core.Services.Audio;
using ChatCaster.Core.Services.Core;
using Serilog;

namespace ChatCaster.Windows.Managers.VoiceRecording;

/// <summary>
/// –¢–æ–Ω–∫–∏–π –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä –∑–∞–ø–∏—Å–∏ –≥–æ–ª–æ—Å–∞ - –¥–µ–ª–µ–≥–∏—Ä—É–µ—Ç –≤—Å—é —Ä–∞–±–æ—Ç—É –º–µ–Ω–µ–¥–∂–µ—Ä–∞–º
/// </summary>
public class VoiceRecordingCoordinator : IVoiceRecordingService, IDisposable
{
    public event EventHandler<RecordingStatusChangedEvent>? StatusChanged;
    public event EventHandler<VoiceRecognitionCompletedEvent>? RecognitionCompleted;

    private readonly IAudioCaptureService _audioCaptureService;
    private readonly ISpeechRecognitionService _speechRecognitionService;
    private readonly IConfigurationService _configurationService;

    private readonly RecordingStateManager _stateManager;
    private readonly AudioBufferManager _bufferManager;
    private readonly RecordingTimerManager _timerManager;

    private bool _isDisposed;

    public RecordingState CurrentState => _stateManager.CurrentState;
    public bool IsRecording => _stateManager.IsRecording;

    public VoiceRecordingCoordinator(
        IAudioCaptureService audioCaptureService,
        ISpeechRecognitionService speechRecognitionService,
        IConfigurationService configurationService)
    {
        _audioCaptureService = audioCaptureService ?? throw new ArgumentNullException(nameof(audioCaptureService));
        _speechRecognitionService =
            speechRecognitionService ?? throw new ArgumentNullException(nameof(speechRecognitionService));
        _configurationService = configurationService ?? throw new ArgumentNullException(nameof(configurationService));

        _stateManager = new RecordingStateManager();
        _bufferManager = new AudioBufferManager();
        _timerManager = new RecordingTimerManager();

        // –ü–æ–¥–ø–∏—Å—ã–≤–∞–µ–º—Å—è –Ω–∞ —Å–æ–±—ã—Ç–∏—è –º–µ–Ω–µ–¥–∂–µ—Ä–æ–≤
        _stateManager.StatusChanged += (s, e) => StatusChanged?.Invoke(this, e);
        _timerManager.AutoStopTriggered += OnAutoStopTriggered;

        // –ü–æ–¥–ø–∏—Å—ã–≤–∞–µ–º—Å—è –Ω–∞ –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã–µ
        _audioCaptureService.AudioDataReceived += OnAudioDataReceived;
    }

    public async Task<bool> StartRecordingAsync(CancellationToken cancellationToken = default)
    {
        try
        {
            if (IsRecording)
            {
                return false;
            }

            Log.Information("üé§ –ù–∞—á–∏–Ω–∞–µ–º –∑–∞–ø–∏—Å—å...");

            // –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
            var config = _configurationService.CurrentConfig;

            if (_configurationService.CurrentConfig.SpeechRecognition.EngineSettings.TryGetValue("ModelSize",
                    out var modelSize))
            {
                Log.Information($"–º–æ–¥–µ–ª—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è {modelSize}");
            }
            else
            {
                Log.Information($"–ú–æ–¥–µ–ª—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è {modelSize} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –∫–æ–Ω—Ñ–∏–≥–µ");
            }

            ;

            var audioConfig = config.Audio;
            var maxSeconds = audioConfig.MaxRecordingSeconds;

            // –ó–∞–ø—É—Å–∫–∞–µ–º –∑–∞—Ö–≤–∞—Ç –∞—É–¥–∏–æ –µ—Å–ª–∏ –Ω–µ –∑–∞–ø—É—â–µ–Ω
            if (!_audioCaptureService.IsCapturing)
            {
                bool captureStarted = await _audioCaptureService.StartCaptureAsync(audioConfig);

                if (!captureStarted)
                {
                    Log.Information("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø—É—Å—Ç–∏—Ç—å –∑–∞—Ö–≤–∞—Ç –∞—É–¥–∏–æ");
                    _stateManager.SetError("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø—É—Å—Ç–∏—Ç—å –∑–∞—Ö–≤–∞—Ç –∞—É–¥–∏–æ");
                    return false;
                }
            }

            // –î–µ–ª–µ–≥–∏—Ä—É–µ–º —Ä–∞–±–æ—Ç—É –º–µ–Ω–µ–¥–∂–µ—Ä–∞–º
            _stateManager.StartRecording();
            _bufferManager.StartBuffering();
            _timerManager.StartAutoStopTimer(maxSeconds);

            Log.Information($"‚úÖ –ó–∞–ø–∏—Å—å –Ω–∞—á–∞–ª–∞—Å—å (–º–∞–∫—Å. {maxSeconds} —Å–µ–∫)");
            return true;
        }
        catch (Exception ex)
        {
            Log.Information($"‚ùå –û—à–∏–±–∫–∞ –Ω–∞—á–∞–ª–∞ –∑–∞–ø–∏—Å–∏: {ex.Message}");
            _stateManager.SetError(ex.Message);
            return false;
        }
    }

    public async Task<VoiceProcessingResult> StopRecordingAsync(CancellationToken cancellationToken = default)
    {
        try
        {
            if (!IsRecording)
            {
                Log.Information("üìù –ó–∞–ø–∏—Å—å –Ω–µ –∏–¥–µ—Ç, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç");
                return new VoiceProcessingResult
                {
                    Success = false, RecognizedText = "", ErrorMessage = "–ó–∞–ø–∏—Å—å –Ω–µ –±—ã–ª–∞ –∞–∫—Ç–∏–≤–Ω–∞"
                };
            }

            Log.Information("üõë –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–ø–∏—Å—å...");

            // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞—Ö–≤–∞—Ç –∞—É–¥–∏–æ
            await _audioCaptureService.StopCaptureAsync();

            // –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –≤ –æ–±—Ä–∞–±–æ—Ç–∫—É
            _stateManager.StartProcessing();

            // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–∞–π–º–µ—Ä
            _timerManager.StopTimer();

            // –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –±—É—Ñ–µ—Ä–∞
            var audioData = _bufferManager.StopBufferingAndGetData();

            if (audioData.Length == 0)
            {
                Log.Information("‚ùå –ù–µ—Ç –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è");
                _stateManager.SetIdle();
                return new VoiceProcessingResult
                {
                    Success = false, RecognizedText = "", ErrorMessage = "–ù–µ—Ç –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã—Ö"
                };
            }

            // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ
            Log.Information("üì§ –ü–æ–ª—É—á–µ–Ω–æ {AudioSize} –±–∞–π—Ç –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è", audioData.Length);

            // –î–û–ë–ê–í–õ–ï–ù–ê –ü–†–û–í–ï–†–ö–ê –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–ò:
            if (!_speechRecognitionService.IsInitialized)
            {
                Log.Warning("‚ùå –†–µ—á–µ–≤–æ–π —Å–µ—Ä–≤–∏—Å –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω, –ø–æ–ø—ã—Ç–∫–∞ –ø–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏...");

                var config = _configurationService.CurrentConfig;
                bool reinitialized = await _speechRecognitionService.InitializeAsync(config.SpeechRecognition);

                if (!reinitialized)
                {
                    Log.Error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–µ—á–µ–≤–æ–π —Å–µ—Ä–≤–∏—Å");
                    _stateManager.SetError("–°–µ—Ä–≤–∏—Å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏ –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω");
                    return new VoiceProcessingResult
                    {
                        Success = false, RecognizedText = "", ErrorMessage = "–°–µ—Ä–≤–∏—Å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏ –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω"
                    };
                }

                Log.Information("‚úÖ –†–µ—á–µ–≤–æ–π —Å–µ—Ä–≤–∏—Å —É—Å–ø–µ—à–Ω–æ –ø–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω");
            }

            var result = await _speechRecognitionService.RecognizeAsync(audioData, cancellationToken);

            // –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º
            _stateManager.CompleteRecording(result.RecognizedText, result.Success, result.ErrorMessage);

            // –£–≤–µ–¥–æ–º–ª—è–µ–º –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏
            RecognitionCompleted?.Invoke(this, new VoiceRecognitionCompletedEvent
            {
                Result = result, AudioDataSize = audioData.Length
            });

            if (result.Success && !string.IsNullOrEmpty(result.RecognizedText))
            {
                Log.Information($"‚úÖ –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: '{result.RecognizedText}'");
            }
            else
            {
                Log.Information($"‚ùå –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å: {result.ErrorMessage}");
            }

            return result;
        }
        catch (Exception ex)
        {
            Log.Information($"‚ùå –û—à–∏–±–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –∑–∞–ø–∏—Å–∏: {ex.Message}");
            _stateManager.SetError(ex.Message);

            return new VoiceProcessingResult
            {
                Success = false, RecognizedText = "", ErrorMessage = ex.Message
            };
        }
    }


    public async Task CancelRecordingAsync()
    {
        try
        {
            if (!IsRecording)
            {
                return;
            }

            Log.Information("‚ùå –û—Ç–º–µ–Ω—è–µ–º –∑–∞–ø–∏—Å—å...");

            // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞—Ö–≤–∞—Ç –∞—É–¥–∏–æ
            await _audioCaptureService.StopCaptureAsync();

            // –î–µ–ª–µ–≥–∏—Ä—É–µ–º –æ—Ç–º–µ–Ω—É –º–µ–Ω–µ–¥–∂–µ—Ä–∞–º
            _stateManager.CancelRecording();
            _bufferManager.CancelBuffering();
            _timerManager.StopTimer();

            Log.Information("‚úÖ –ó–∞–ø–∏—Å—å –æ—Ç–º–µ–Ω–µ–Ω–∞");
        }
        catch (Exception ex)
        {
            Log.Information($"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–º–µ–Ω—ã –∑–∞–ø–∏—Å–∏: {ex.Message}");
            _stateManager.SetError(ex.Message);
        }
    }

    public async Task<bool> TestMicrophoneAsync()
    {
        try
        {
            Log.Information("üîç –¢–µ—Å—Ç–∏—Ä—É–µ–º –º–∏–∫—Ä–æ—Ñ–æ–Ω...");
            return await _audioCaptureService.TestMicrophoneAsync();
        }
        catch (Exception ex)
        {
            Log.Information($"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞: {ex.Message}");
            return false;
        }
    }

    public async Task<VoiceProcessingResult> ProcessAudioDataAsync(byte[] audioData,
        CancellationToken cancellationToken = default)
    {
        try
        {
            Log.Information($"üì§ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º {audioData.Length} –±–∞–π—Ç –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã—Ö");
            return await _speechRecognitionService.RecognizeAsync(audioData, cancellationToken);
        }
        catch (Exception ex)
        {
            Log.Information($"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ: {ex.Message}");
            return new VoiceProcessingResult
            {
                Success = false, RecognizedText = "", ErrorMessage = ex.Message
            };
        }
    }

    private async void OnAutoStopTriggered(object? sender, EventArgs e)
    {
        try
        {
            await StopRecordingAsync();
        }
        catch (Exception ex)
        {
            Log.Information($"‚ùå –û—à–∏–±–∫–∞ –∞–≤—Ç–æ–æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –∑–∞–ø–∏—Å–∏: {ex.Message}");
        }
    }

    private void OnAudioDataReceived(object? sender, byte[] audioData)
    {
        _bufferManager.OnAudioDataReceived(audioData);
    }

    public void Dispose()
    {
        if (!_isDisposed)
        {
            // –û—Ç–ø–∏—Å—ã–≤–∞–µ–º—Å—è –æ—Ç —Å–æ–±—ã—Ç–∏–π
            _audioCaptureService.AudioDataReceived -= OnAudioDataReceived;
            _timerManager.AutoStopTriggered -= OnAutoStopTriggered;

            // –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º —Ä–µ—Å—É—Ä—Å—ã –º–µ–Ω–µ–¥–∂–µ—Ä–æ–≤
            _timerManager?.Dispose();

            _isDisposed = true;
        }
    }
}
