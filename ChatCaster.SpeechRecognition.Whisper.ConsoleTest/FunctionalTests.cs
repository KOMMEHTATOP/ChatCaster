using ChatCaster.Core.Models;
using ChatCaster.Core.Services;
using ChatCaster.SpeechRecognition.Whisper.Constants;
using ChatCaster.SpeechRecognition.Whisper.Models;
using ChatCaster.SpeechRecognition.Whisper.Services;
using ChatCaster.SpeechRecognition.Whisper.Utils;
using Microsoft.Extensions.Logging;
using Serilog;

namespace ChatCaster.SpeechRecognition.Whisper.ConsoleTest;

/// <summary>
/// –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Ç–µ—Å—Ç—ã –±–∞–∑–æ–≤–æ–π —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ Whisper –º–æ–¥—É–ª—è
/// </summary>
public class FunctionalTests
{
    private readonly ILogger<FunctionalTests> _logger;
    private readonly ISpeechRecognitionService _speechService;
    private readonly WhisperModelManager _modelManager;
    private readonly AudioConverter _audioConverter;
    private readonly ModelDownloader _modelDownloader;

    public FunctionalTests(
        ILogger<FunctionalTests> logger,
        ISpeechRecognitionService speechService,
        WhisperModelManager modelManager,
        AudioConverter audioConverter,
        ModelDownloader modelDownloader)
    {
        _logger = logger;
        _speechService = speechService;
        _modelManager = modelManager;
        _audioConverter = audioConverter;
        _modelDownloader = modelDownloader;
    }

    /// <summary>
    /// –¢–µ—Å—Ç–∏—Ä—É–µ—Ç –∑–∞–≥—Ä—É–∑–∫—É –º–æ–¥–µ–ª–µ–π
    /// </summary>
    public async Task TestModelDownloadAsync()
    {
        Log.Information("\nüîΩ Testing model download and management...");

        // –¢–µ—Å—Ç–∏—Ä—É–µ–º tiny –º–æ–¥–µ–ª—å (—Å–∞–º–∞—è –º–∞–ª–µ–Ω—å–∫–∞—è)
        var modelSize = WhisperConstants.ModelSizes.Tiny;
        var modelDirectory = Path.Combine(Directory.GetCurrentDirectory(), "models");

        try
        {
            // –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏
            var availability = await _modelManager.CheckModelAvailabilityAsync(modelSize, modelDirectory);
            Log.Information($"   Model {modelSize} availability:");
            Log.Information($"   - Local: {availability.IsAvailableLocally}");
            Log.Information($"   - Download: {availability.IsAvailableForDownload}");
            Log.Information($"   - Supported: {availability.IsSupported}");

            if (availability.IsAvailableForDownload)
            {
                Log.Information($"   - Download size: {availability.DownloadSizeBytes / 1024.0 / 1024.0:F1} MB");
            }

            // –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –º–æ–¥–µ–ª—å (–∑–∞–≥—Ä—É–∂–∞–µ–º –µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
            Log.Information($"   Preparing model {modelSize}...");
            var stopwatch = System.Diagnostics.Stopwatch.StartNew();
            
            var modelPath = await _modelManager.PrepareModelAsync(modelSize, modelDirectory);
            stopwatch.Stop();

            Log.Information($"   ‚úÖ Model ready: {Path.GetFileName(modelPath)}");
            Log.Information($"   ‚è±Ô∏è Preparation time: {stopwatch.ElapsedMilliseconds}ms");

            // –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∞–π–ª –º–æ–¥–µ–ª–∏
            var fileInfo = new FileInfo(modelPath);
            Log.Information($"   üìÅ File size: {fileInfo.Length / 1024.0 / 1024.0:F1} MB");
            Log.Information($"   üìÖ Last modified: {fileInfo.LastWriteTime:yyyy-MM-dd HH:mm:ss}");
        }
        catch (Exception ex)
        {
            Log.Information($"   ‚ùå Model download test failed: {ex.Message}");
            _logger.LogError(ex, "Model download test failed");
            throw;
        }
    }

    /// <summary>
    /// –¢–µ—Å—Ç–∏—Ä—É–µ—Ç –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—é –∞—É–¥–∏–æ
    /// </summary>
    public async Task TestAudioConversionAsync()
    {
        Log.Information("\nüéµ Testing audio conversion...");

        try
        {
            // –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –∞—É–¥–∏–æ —Å–∏–≥–Ω–∞–ª (—Å–∏–Ω—É—Å–æ–∏–¥–∞)
            var testAudio = GenerateTestAudio(duration: 3.0, frequency: 440.0); // 3 —Å–µ–∫—É–Ω–¥—ã, 440 Hz
            Log.Information($"   Generated test audio: {testAudio.Length} bytes");

            // –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∞—É–¥–∏–æ
            var audioInfo = _audioConverter.GetAudioInfo(
                testAudio,
                WhisperConstants.Audio.RequiredSampleRate,
                WhisperConstants.Audio.RequiredChannels,
                WhisperConstants.Audio.RequiredBitsPerSample);

            Log.Information($"   Audio info: {audioInfo}");
            Log.Information($"   Compatible with Whisper: {audioInfo.IsCompatibleWithWhisper}");

            // –¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—é
            var stopwatch = System.Diagnostics.Stopwatch.StartNew();
            var samples = await _audioConverter.ConvertToSamplesAsync(testAudio, CancellationToken.None);
            stopwatch.Stop();

            Log.Information($"   ‚úÖ Conversion completed: {samples.Length} samples");
            Log.Information($"   ‚è±Ô∏è Conversion time: {stopwatch.ElapsedMilliseconds}ms");

            // –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            var avgAmplitude = samples.Select(Math.Abs).Average();
            var maxAmplitude = samples.Select(Math.Abs).Max();
            Log.Information($"   üìä Average amplitude: {avgAmplitude:F4}");
            Log.Information($"   üìä Max amplitude: {maxAmplitude:F4}");

            // –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã
            await TestDifferentAudioFormatsAsync();
        }
        catch (Exception ex)
        {
            Log.Information($"   ‚ùå Audio conversion test failed: {ex.Message}");
            _logger.LogError(ex, "Audio conversion test failed");
            throw;
        }
    }

    /// <summary>
    /// –¢–µ—Å—Ç–∏—Ä—É–µ—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏
    /// </summary>
    public async Task TestSpeechRecognitionAsync()
    {
        Log.Information("\nüé§ Testing speech recognition...");

        try
        {
            // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–≤–∏–∂–æ–∫
            Log.Information("   Initializing speech recognition engine...");
            var config = CreateTestConfig();
            
            var initStopwatch = System.Diagnostics.Stopwatch.StartNew();
            var initialized = await _speechService.InitializeAsync(config);
            initStopwatch.Stop();

            if (!initialized)
            {
                throw new InvalidOperationException("Failed to initialize speech recognition engine");
            }

            Log.Information($"   ‚úÖ Engine initialized in {initStopwatch.ElapsedMilliseconds}ms");

            // –ü–æ–ª—É—á–∞–µ–º –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –¥–≤–∏–∂–∫–∞
            var capabilities = await _speechService.GetCapabilitiesAsync();
            Log.Information($"   üîß Engine capabilities:");
            Log.Information($"   - Language auto-detection: {capabilities.SupportsLanguageAutoDetection}");
            Log.Information($"   - GPU acceleration: {capabilities.SupportsGpuAcceleration}");
            Log.Information($"   - Real-time processing: {capabilities.SupportsRealTimeProcessing}");
            Log.Information($"   - Requires internet: {capabilities.RequiresInternetConnection}");
            Log.Information($"   - Sample rates: {string.Join(", ", capabilities.SupportedSampleRates)}");

            // –ü–æ–ª—É—á–∞–µ–º –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —è–∑—ã–∫–∏
            var languages = await _speechService.GetSupportedLanguagesAsync();
            Log.Information($"   üåê Supported languages: {string.Join(", ", languages.Take(5))}...");

            // –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Å —Ç–µ—Å—Ç–æ–≤—ã–º –∞—É–¥–∏–æ
            await TestRecognitionWithDifferentInputsAsync();
        }
        catch (Exception ex)
        {
            Log.Information($"   ‚ùå Speech recognition test failed: {ex.Message}");
            _logger.LogError(ex, "Speech recognition test failed");
            throw;
        }
    }

    #region Private Methods

    private byte[] GenerateTestAudio(double duration, double frequency)
    {
        var sampleRate = WhisperConstants.Audio.RequiredSampleRate;
        var channels = WhisperConstants.Audio.RequiredChannels;
        var bitsPerSample = WhisperConstants.Audio.RequiredBitsPerSample;
        
        var totalSamples = (int)(duration * sampleRate);
        var audioData = new byte[totalSamples * channels * (bitsPerSample / 8)];

        for (int i = 0; i < totalSamples; i++)
        {
            // –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–∏–Ω—É—Å–æ–∏–¥—É —Å –∑–∞—Ç—É—Ö–∞–Ω–∏–µ–º –¥–ª—è –±–æ–ª–µ–µ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ–≥–æ –∑–≤—É–∫–∞
            var time = i / (double)sampleRate;
            var amplitude = Math.Sin(2 * Math.PI * frequency * time) * Math.Exp(-time * 0.5);
            var sample = (short)(amplitude * 16384); // 50% –æ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –∞–º–ø–ª–∏—Ç—É–¥—ã

            // –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ little-endian —Ñ–æ—Ä–º–∞—Ç–µ
            var sampleBytes = BitConverter.GetBytes(sample);
            audioData[i * 2] = sampleBytes[0];
            audioData[i * 2 + 1] = sampleBytes[1];
        }

        return audioData;
    }

    private async Task TestDifferentAudioFormatsAsync()
    {
        Log.Information("   Testing different audio formats...");

        var testCases = new[]
        {
            new { SampleRate = 8000, Channels = 1, BitsPerSample = 16, Description = "8kHz Mono 16-bit" },
            new { SampleRate = 44100, Channels = 2, BitsPerSample = 16, Description = "44.1kHz Stereo 16-bit" },
            new { SampleRate = 48000, Channels = 1, BitsPerSample = 32, Description = "48kHz Mono 32-bit" }
        };

        foreach (var testCase in testCases)
        {
            try
            {
                var testAudio = GenerateTestAudioWithFormat(1.0, 440.0, testCase.SampleRate, testCase.Channels, testCase.BitsPerSample);
                var samples = await _audioConverter.ConvertToSamplesAsync(testAudio, testCase.SampleRate, testCase.Channels, testCase.BitsPerSample, CancellationToken.None);
                Log.Information($"   ‚úÖ {testCase.Description}: {samples.Length} samples");
            }
            catch (Exception ex)
            {
                Log.Information($"   ‚ùå {testCase.Description}: {ex.Message}");
            }
        }
    }

    private byte[] GenerateTestAudioWithFormat(double duration, double frequency, int sampleRate, int channels, int bitsPerSample)
    {
        var totalSamples = (int)(duration * sampleRate);
        var bytesPerSample = bitsPerSample / 8;
        var audioData = new byte[totalSamples * channels * bytesPerSample];

        for (int i = 0; i < totalSamples; i++)
        {
            var time = i / (double)sampleRate;
            var amplitude = Math.Sin(2 * Math.PI * frequency * time) * 0.5;

            for (int ch = 0; ch < channels; ch++)
            {
                var sampleIndex = (i * channels + ch) * bytesPerSample;

                if (bitsPerSample == 16)
                {
                    var sample = (short)(amplitude * 16384);
                    var sampleBytes = BitConverter.GetBytes(sample);
                    audioData[sampleIndex] = sampleBytes[0];
                    audioData[sampleIndex + 1] = sampleBytes[1];
                }
                else if (bitsPerSample == 32)
                {
                    var sample = (int)(amplitude * 1073741824); // 2^30
                    var sampleBytes = BitConverter.GetBytes(sample);
                    Array.Copy(sampleBytes, 0, audioData, sampleIndex, 4);
                }
            }
        }

        return audioData;
    }

    private async Task TestRecognitionWithDifferentInputsAsync()
    {
        Log.Information("   Testing recognition with different inputs...");

        var testCases = new[]
        {
            new { Duration = 1.0, Frequency = 440.0, Description = "Short tone (1s)" },
            new { Duration = 3.0, Frequency = 880.0, Description = "Medium tone (3s)" },
            new { Duration = 0.5, Frequency = 220.0, Description = "Very short tone (0.5s)" }
        };

        foreach (var testCase in testCases)
        {
            try
            {
                Log.Information($"     Testing: {testCase.Description}");
                var testAudio = GenerateTestAudio(testCase.Duration, testCase.Frequency);
                
                var stopwatch = System.Diagnostics.Stopwatch.StartNew();
                var result = await _speechService.RecognizeAsync(testAudio);
                stopwatch.Stop();

                Log.Information($"     ‚úÖ Recognition completed in {stopwatch.ElapsedMilliseconds}ms");
                Log.Information($"     üìù Success: {result.Success}");
                Log.Information($"     üéØ Confidence: {result.Confidence:F2}");
                Log.Information($"     üìÑ Text: '{result.RecognizedText ?? "null"}'");
                
                if (!string.IsNullOrEmpty(result.ErrorMessage))
                {
                    Log.Information($"     ‚ö†Ô∏è Error: {result.ErrorMessage}");
                }
            }
            catch (Exception ex)
            {
                Log.Information($"     ‚ùå {testCase.Description} failed: {ex.Message}");
            }
        }
    }

    private SpeechRecognitionConfig CreateTestConfig()
    {
        return new SpeechRecognitionConfig
        {
            Engine = WhisperConstants.EngineName,
            Language = "auto",
            UseGpuAcceleration = false,
            MaxTokens = WhisperConstants.Performance.DefaultMaxTokens,
            EngineSettings = new Dictionary<string, object>
            {
                [WhisperConstants.SettingsKeys.ModelSize] = WhisperConstants.ModelSizes.Tiny,
                [WhisperConstants.SettingsKeys.Temperature] = 0.0f,
                [WhisperConstants.SettingsKeys.UseVAD] = true,
                [WhisperConstants.SettingsKeys.ThreadCount] = 2
            }
        };
    }

    #endregion
}